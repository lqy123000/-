## 机器学习概念

### 框架处理
合适的特征应该是具体且可量化的
### 降低损失
批量大小越大，出现冗余的可能性就越高。小批量 SGD 可以减少 SGD 中的杂乱样本数量，但仍然比全批量更高效。基于大型数据集执行梯度下降法时，在小批量或甚至包含一个样本的批量上执行梯度下降法通常比全批量更高效。
### 泛化
过拟合是由于模型的复杂程度超出所需程度而造成的。机器学习的基本冲突是适当拟合我们的数据，但也要尽可能简单地拟合数据。
### 验证
如果使用测试集作为验证集，并以基于测试数据的评估结果为指导来选择和更改各种模型超参数，例如学习速率和特征，可能导致我们不知不觉地拟合我们的特定测试集的特性，因此有必要单独划分验证集。
### 表示：良好特征的特点
避免很少使用的离散特征值，最好具有清晰明确的含义（不用类似于UUID这种随机的标志），不要将“神奇”的值与实际数据混为一谈（比如用-1来代替无效值，更好的办法是另外存储一个bool值），考虑上游不稳定性（特征的定义不应随时间变化，如某一代码原来表示一个事物后来换为另一事物）
### 表示：清理数据
* 缩放特征值：
如果某个特征集只包含一个特征，则缩放可以提供的实际好处微乎其微或根本没有。不过，如果特征集包含多个特征，则缩放特征可以带来以下优势：帮助梯度下降法更快速地收敛；帮助避免“NaN 陷阱”，在这种陷阱中，模型中的一个数值变成 NaN，并且模型中的所有其他数值最终也会因数学运算而变成 NaN；帮助模型为每个特征确定合适的权重。主要方法：max-min和z-score。
* 处理极端离群值：对数缩放，“限制”最大值。
* 分箱
### 表正则化
执行 L2 正则化对模型具有以下影响：
* 使权重值接近于 0（但并非正好为 0）
* 使权重的平均值接近于 0，且呈正态（钟形曲线或高斯曲线）分布。

在选择 lambda 值时，目标是在简单化和训练数据拟合之间达到适当的平衡：
* 如果您的 lambda 值过高，则模型会非常简单，但是您将面临数据欠拟合的风险。您的模型将无法从训练数据中获得足够的信息来做出有用的预测。
* 如果您的 lambda 值过低，则模型会比较复杂，并且您将面临数据过拟合的风险。您的模型将因获得过多训练数据特点方面的信息而无法泛化到新数据。
* 理想的 lambda 值生成的模型可以很好地泛化到以前未见过的新数据。 遗憾的是，理想的 lambda 值取决于数据，因此您需要手动或自动进行一些调整。

1.癌症预测
特征中包含了医院名称，而某些医院本来就是主要治疗癌症甚至名称就包含“癌”字，因此出现“标签泄漏”问题，测试准确率高，却无法在实际未分配医院的新患者身上使用
2.18世纪的文学，使用作者的一些句子来推断作者的政治派别
拆分训练、验证、测试集时，如果将各集合都包含所有作者的部分句子，则准确率很高（高到离谱）；如果各集合所包含的作者不重叠，这准确率较低。实际上，后者才是适合实用的模型，因为我们要预测的是一个未知政治派别的作者，不可能将他的数据放到训练集。所以验证集尤其是测试集更应该根据实际需求来收集数据以得到合理的评价
3.现实世界应用准则
可以先建立一个简单的模型，如线性模型，先确保数据管道的正确性，使用简单且可观察的指标进行训练和评估，将模型配置视为代码进行审核并记录在案，记下所有实验的结果，尤其是“失败”的结果。
