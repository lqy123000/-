# 谷歌机器学习速成课程笔记
[谷歌机器学习速成课程](https://developers.google.cn/machine-learning/crash-course/)个人笔记，主要是对工程实践比较有价值的要点总结，部分为个人总结，部分直接摘自课程。作为个人笔记，未包含一些可能重要但自己已经熟悉的内容。

## 机器学习概念

### 框架处理
合适的特征应该是具体且可量化的。

### 降低损失
批量大小越大，出现冗余的可能性就越高。小批量 SGD 可以减少 SGD 中的杂乱样本数量，但仍然比全批量更高效。基于大型数据集执行梯度下降法时，在小批量或甚至包含一个样本的批量上执行梯度下降法通常比全批量更高效。

### 泛化
过拟合是由于模型的复杂程度超出所需程度而造成的。机器学习的基本冲突是适当拟合我们的数据，但也要尽可能简单地拟合数据。

### 验证
如果使用测试集作为验证集，并以基于测试数据的评估结果为指导来选择和更改各种模型超参数，例如学习速率和特征，可能导致我们不知不觉地拟合我们的特定测试集的特性，因此有必要单独划分验证集。

### 表示：良好特征的特点
避免很少使用的离散特征值，最好具有清晰明确的含义（不用类似于UUID这种随机的标志），不要将“神奇”的值与实际数据混为一谈（比如用-1来代替无效值，更好的办法是另外存储一个bool值），考虑上游不稳定性（特征的定义不应随时间变化，如某一代码原来表示一个事物后来换为另一事物）。

### 表示：清理数据
* 缩放特征值：
如果某个特征集只包含一个特征，则缩放可以提供的实际好处微乎其微或根本没有。不过，如果特征集包含多个特征，则缩放特征可以带来以下优势：帮助梯度下降法更快速地收敛；帮助避免“NaN 陷阱”，在这种陷阱中，模型中的一个数值变成 NaN，并且模型中的所有其他数值最终也会因数学运算而变成 NaN；帮助模型为每个特征确定合适的权重。主要方法：max-min和z-score。
* 处理极端离群值：对数缩放，“限制”最大值。
* 分箱。

### 正则化
执行 L2 正则化对模型具有以下影响：
* 使权重值接近于 0（但并非正好为 0）。
* 使权重的平均值接近于 0，且呈正态（钟形曲线或高斯曲线）分布。

在选择 lambda 值时，目标是在简单化和训练数据拟合之间达到适当的平衡：
* 如果您的 lambda 值过高，则模型会非常简单，但是您将面临数据欠拟合的风险。您的模型将无法从训练数据中获得足够的信息来做出有用的预测。
* 如果您的 lambda 值过低，则模型会比较复杂，并且您将面临数据过拟合的风险。您的模型将因获得过多训练数据特点方面的信息而无法泛化到新数据。
* 理想的 lambda 值生成的模型可以很好地泛化到以前未见过的新数据。 遗憾的是，理想的 lambda 值取决于数据，因此您需要手动或自动进行一些调整。

### 分类
#### 预测偏差
`预测偏差 = 预测平均值 - 数据集中相应标签的平均值`

如果出现非常高的非零预测偏差，则说明模型某处存在错误，因为这表明模型对正类别标签的出现频率预测有误。

例如，已知 1% 的邮件是垃圾邮件，但是模型预测电子邮件是垃圾邮件的平均可能性为 20%，那么我们可以得出结论，该模型出现了预测偏差。

造成预测偏差的可能原因包括：
* 特征集不完整
* 数据集混乱
* 模型实现流水线中有错误？
* 训练样本有偏差
* 正则化过强

如果可能的话，避免添加校准层。使用校准层的项目往往会对其产生依赖 - 使用校准层来修复模型的所有错误。最终，维护校准层可能会令人苦不堪言。

### L₁正则化
可以将 L2 的导数的作用理解为每次移除权重的 x%，将 L1 的导数的作用理解为每次从权重中减去一个常数，从而理解为什么 L2 通常不会使权重变为 0 而 L1 使权重变为 0 。

### 训练神经网络
* ReLU 激活函数有助于防止梯度消失。
* 批标准化可以降低学习速率，因而有助于防止梯度爆炸。
* 降低学习速率有助于防止 ReLU 单元消失(输入加权和低于 0)。

### 多类别神经网络
在多类别问题中，Softmax 会为每个类别分配一个用小数表示的概率，这些用小数表示的概率相加之和必须是 1.0。与其他方式相比，这种附加限制有助于让训练过程更快速地收敛。

Softmax 假设每个样本只是一个类别的成员。但是，一些样本可以同时是多个类别的成员。对于此类示例：
* 不能使用 Softmax
* 必须依赖多个逻辑回归

### 嵌入
#### 标准降维技术
PCA

#### Word2vec

## 机器学习工程

### 静态训练与动态训练
从广义上讲，训练模型的方式有两种：
* **静态模型**采用离线训练方式。也就是说，我们只训练模型一次，然后使用训练后的模型一段时间。
* **动态模型**采用在线训练方式。也就是说，数据会不断进入系统，我们通过不断地更新系统将这些数据整合到模型中。

静态训练和动态训练的选择由以下几点决定：
* 静态模型更易于构建和测试。
* 动态模型可以适应不断变化的数据。世界瞬息万变。基于去年的数据作出的销售预测很可能无法成功预测下一年的情况。

静态训练创建和维护成本低于动态训练，但是即便是静态训练，也必须监控输入数据是否发生变化。

### 静态推理与动态推理
* 离线推理，指的是使用 MapReduce 或类似方法批量进行所有可能的预测。然后，将预测记录到 SSTable 或 Bigtable 中，并将它们提供给一个缓存/查询表。
* 在线推理，指的是使用服务器根据需要进行预测。

以下是离线推理的优缺点：
* 优点：不需要过多担心推理成本。
* 优点：可以使用批量方法或某些巨型 MapReduce 方法。
* 优点：可以在推送之前对预测执行后期验证。
* 缺点：只能对我们知晓的数据进行预测，不适用于存在长尾的情况。
* 缺点：更新可能延迟数小时或数天。

以下是在线推理的优缺点：
* 优点：可在新项目加入时对其进行预测，非常适合存在长尾的情况。
* 缺点：计算量非常大，对延迟较为敏感，可能会限制模型的复杂度。
* 缺点：监控需求更多。

### 数据依赖关系
要避免反馈环。例如，来自某些模型的结果反过来是同一模型的直接或间接输入特征。反馈环可能会触发郁金香狂热效应。

## 机器学习现实世界应用示例

### 癌症预测
特征中包含了医院名称，而某些医院本来就是主要治疗癌症甚至名称就包含“癌”字，因此出现“标签泄漏”问题，测试准确率高，却无法在实际未分配医院的新患者身上使用。

### 18世纪的文学
使用作者的一些句子来推断作者的政治派别。

拆分训练、验证、测试集时，如果将各集合都包含所有作者的部分句子，则准确率很高（高到离谱）；如果各集合所包含的作者不重叠，这准确率较低。实际上，后者才是适合实用的模型，因为我们要预测的是一个未知政治派别的作者，不可能将他的数据放到训练集。所以验证集尤其是测试集更应该根据实际需求来收集数据以得到合理的评价。

### 现实世界应用准则
有效的机器学习准则：
* 确保第一个模型简单易用。
* 着重确保数据管道的正确性。
* 使用简单且可观察的指标进行训练和评估。
* 拥有并监控您的输入特征。
* 将您的模型配置视为代码：进行审核并记录在案。
* 记下所有实验的结果，尤其是“失败”的结果。

可以先建立一个简单的模型，如线性模型，先确保数据管道的正确性。
